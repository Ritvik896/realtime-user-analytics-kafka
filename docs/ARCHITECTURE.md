System Architecture
Complete technical architecture of the Real-time User Analytics platform.

ğŸ—ï¸ High-Level Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERACTION LAYER                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Users click, purchase, watch videos, search, etc.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 1: EVENT GENERATION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mock Event Generator (Pydantic Models)                     â”‚
â”‚  - UserEvent (base)                                         â”‚
â”‚  - PurchaseEvent, VideoWatchEvent, ClickEvent, etc.        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 1: KAFKA PRODUCER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Validates & sends events to Kafka                          â”‚
â”‚  - Error handling & retries                                 â”‚
â”‚  - Delivery confirmation                                    â”‚
â”‚  - Metrics tracking                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         KAFKA MESSAGE BROKER (Central Hub)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Topics:                                                     â”‚
â”‚  - user-events (all raw events)                             â”‚
â”‚  - user-analytics (processed events)                        â”‚
â”‚  - user-anomalies (flagged events)                          â”‚
â”‚                                                              â”‚
â”‚  Properties:                                                 â”‚
â”‚  - Scalable: 1M+ events/sec                                â”‚
â”‚  - Reliable: No message loss                               â”‚
â”‚  - Distributed: Partitioned & replicated                   â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚                     â”‚                  â”‚
  â”‚ (Partition 0)       â”‚ (Partition 1)    â”‚ (Partition 2)
  â”‚                     â”‚                  â”‚
  â–¼                     â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: KAFKA CONSUMERS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Consumer 1    Consumer 2    Consumer 3                     â”‚
â”‚  â”œâ”€ Read       â”œâ”€ Read       â”œâ”€ Read                        â”‚
â”‚  â”œâ”€ Validate   â”œâ”€ Validate   â”œâ”€ Validate                    â”‚
â”‚  â””â”€ Process    â””â”€ Process    â””â”€ Process                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PHASE 2: DATABASE LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PostgreSQL (Primary Storage)                               â”‚
â”‚  â”œâ”€ events (1M+ rows) - All user events                    â”‚
â”‚  â”œâ”€ users - User profiles & stats                          â”‚
â”‚  â”œâ”€ failed_events - Dead-letter queue                      â”‚
â”‚  â””â”€ daily_stats - Aggregated data                          â”‚
â”‚                                                              â”‚
â”‚  Features:                                                   â”‚
â”‚  - Connection pooling (20 connections)                      â”‚
â”‚  - Indexed queries (user_id, timestamp, type)              â”‚
â”‚  - ACID transactions                                        â”‚
â”‚  - Migrations (Alembic)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ PHASE 3:     â”‚  â”‚ PHASE 4:     â”‚  â”‚ PHASE 5:     â”‚
  â”‚ STREAM       â”‚  â”‚ REST API     â”‚  â”‚ ML PIPELINE  â”‚
  â”‚ PROCESSOR    â”‚  â”‚              â”‚  â”‚              â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Aggregations â”‚  â”‚ FastAPI      â”‚  â”‚ Anomaly      â”‚
  â”‚ Windowing    â”‚  â”‚ Endpoints    â”‚  â”‚ Detection    â”‚
  â”‚ Enrichment   â”‚  â”‚ Validation   â”‚  â”‚ Churn Pred   â”‚
  â”‚ Metrics      â”‚  â”‚ Docs (Swagger)  â”‚ Scoring      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 6: MONITORING & VISUALIZATION             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Prometheus (Metrics Collection)                            â”‚
â”‚  â”œâ”€ Event throughput                                        â”‚
â”‚  â”œâ”€ Kafka consumer lag                                      â”‚
â”‚  â”œâ”€ Database latency                                        â”‚
â”‚  â””â”€ Error rates                                             â”‚
â”‚                                                              â”‚
â”‚  Grafana (Dashboards)                                       â”‚
â”‚  â”œâ”€ Overview dashboard                                      â”‚
â”‚  â”œâ”€ Kafka metrics                                           â”‚
â”‚  â”œâ”€ Business KPIs                                           â”‚
â”‚  â””â”€ System health                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 7: TESTING & CI/CD                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Unit Tests â†’ Integration Tests â†’ E2E Tests                 â”‚
â”‚  GitHub Actions â†’ Automated Deployment                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”„ Data Flow Example
Scenario: User makes a purchase
1. USER ACTION (10:30:45 AM)
   â””â”€ User clicks "Buy Now" button

2. EVENT GENERATION (Phase 1)
   â”œâ”€ Event object created (PurchaseEvent)
   â”œâ”€ Pydantic validation
   â””â”€ Sent to Kafka Producer

3. KAFKA PRODUCER (Phase 1)
   â”œâ”€ Serialized to JSON
   â”œâ”€ Sent to Kafka topic: user-events
   â”œâ”€ Partition 2, Offset 1000234
   â””â”€ Replicated to 3 brokers

4. KAFKA BROKER
   â”œâ”€ Event stored in partition
   â””â”€ Available for consumers

5. KAFKA CONSUMER (Phase 2)
   â”œâ”€ Read from partition
   â”œâ”€ Deserialize JSON
   â””â”€ Parse to UserEvent

6. VALIDATION (Phase 2)
   â”œâ”€ Check all required fields
   â”œâ”€ Validate data types
   â””â”€ Reject if invalid

7. DATABASE STORAGE (Phase 2)
   â”œâ”€ INSERT INTO events
   â”œâ”€ UPDATE users table
   â””â”€ Index for fast queries

8. STREAM PROCESSING (Phase 3)
   â”œâ”€ Real-time aggregation
   â”œâ”€ Update daily stats
   â””â”€ Calculate metrics

9. ML PIPELINE (Phase 5)
   â”œâ”€ Feature extraction
   â”œâ”€ Anomaly detection
   â”œâ”€ Fraud scoring: 0.05 (normal)
   â””â”€ Store result

10. CACHE & API (Phase 4)
    â”œâ”€ Data available
    â”œâ”€ Endpoint ready
    â””â”€ Response < 100ms

11. MONITORING (Phase 6)
    â”œâ”€ Metrics recorded
    â”œâ”€ Throughput updated
    â””â”€ Dashboard refreshed

12. RESULT
    â””â”€ Event processed end-to-end in < 100ms

ğŸ› ï¸ Technology Stack by Layer
Event Generation Layer

Pydantic: Data validation
Python 3.12: Core language
UUID: Unique identifiers

Message Queue Layer

Apache Kafka: Distributed message broker
Zookeeper: Cluster coordination
Confluent Kafka: Python client

Stream Processing Layer

Kafka Streams / Custom Python: Processing logic
Window operations: Time-based aggregations
State management: Tracking metrics

Storage Layer

PostgreSQL: Primary database
SQLAlchemy: ORM
Alembic: Schema migrations
Connection pooling: Performance

ML Layer

scikit-learn: Machine learning
Isolation Forest: Anomaly detection
Model persistence: Joblib

API Layer

FastAPI: Web framework
Pydantic: Request/response validation
Swagger/OpenAPI: Documentation

Monitoring Layer

Prometheus: Metrics collection
Grafana: Visualization
Custom metrics: Application-level

Infrastructure Layer

Docker: Containerization
Docker Compose: Orchestration
Terraform: Infrastructure as Code (Phase 7)


ğŸ“Š Data Model
Events Table
sqlCREATE TABLE events (
    event_id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(50) INDEXED,
    session_id VARCHAR(36),
    event_type VARCHAR(50) INDEXED,
    timestamp DATETIME INDEXED,
    device VARCHAR(20),
    country VARCHAR(2) INDEXED,
    value DECIMAL(15, 2),
    data JSON,
    created_at DATETIME,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);
Users Table
sqlCREATE TABLE users (
    user_id VARCHAR(50) PRIMARY KEY,
    first_seen DATETIME,
    last_seen DATETIME,
    total_events INTEGER,
    total_purchases DECIMAL(15, 2),
    total_spent DECIMAL(15, 2),
    country VARCHAR(2) INDEXED,
    metadata JSON
);
Failed Events (Dead-Letter Queue)
sqlCREATE TABLE failed_events (
    id INTEGER PRIMARY KEY,
    event_id VARCHAR(36),
    error_reason TEXT,
    error_type VARCHAR(100),
    raw_data TEXT,
    timestamp DATETIME INDEXED
);

âš¡ Performance Characteristics
Throughput

Target: 1M+ events/second
Current (Phase 1): 10.2 events/sec (mock)
Bottleneck: Network â†’ Kafka â†’ Database

Latency

End-to-end: < 100ms from event to database
Producer: < 10ms
Kafka: < 50ms
Consumer: < 20ms
Database: < 20ms

Reliability

Message loss: 0 (acks=all)
Duplicate handling: Consumer group tracking
Error handling: Dead-letter queue

Storage

Events/day: 1-2 million
Storage/year: ~500GB (uncompressed)
Retention: 24 hours to 1 year (configurable)


ğŸ” Security Considerations
Authentication

Kafka SASL/SCRAM (production)
PostgreSQL password authentication
API key validation (Phase 4)

Authorization

Role-based access control
Topic ACLs in Kafka
Database user permissions

Data Protection

Encryption in transit (TLS)
Encryption at rest (full-disk)
PII data handling


ğŸš€ Scaling Strategy
Horizontal Scaling

Add Kafka partitions (more parallelism)
Add consumer instances (load balancing)
Add database replicas (read scaling)

Vertical Scaling

Increase machine resources
Optimize database queries
Tune connection pools

Caching

Redis for hot data
In-memory caches
Query result caching


ğŸ”„ Deployment Patterns
Local Development

Docker Compose (all services)
Direct service communication
Mock data generation

Staging

Kubernetes cluster
Small node pool
Real data sample

Production

Multi-zone Kubernetes
Load balancers
Auto-scaling groups
Backup & disaster recovery


ğŸ“ˆ Monitoring & Observability
Metrics

Event throughput (events/sec)
Consumer lag (messages behind)
Database latency (ms)
Error rates (%)

Logging

Structured JSON logging
Centralized log aggregation
Searchable by user_id, event_id

Tracing

Request tracing (future)
End-to-end latency tracking
Performance bottleneck identification


Architecture designed for production scalability and reliability! ğŸš€